{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Train a GPT-2 Text-Generating Model w/ GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UpwardTrajectory/auto-rapper/blob/master/auto_rapper_w_gpu_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "source": [
        "# Auto-Rapper\n",
        "##  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
        "## WARNING -- Lyrics are unpredictable and may be explicit or disturbing -- WARNING\n",
        "\n",
        "Based on the Colab by  [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: June 21th, 2019*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE",
        "colab_type": "text"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory now uses an Nvidia T4 GPU, which is slightly faster than the old Nvidia K80 GPU for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab_type": "code",
        "outputId": "99c474bc-55a0-4579-c662-f83e0277d859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 19 23:20:25 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8    15W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are two sizes of GPT-2:\n",
        "\n",
        "* `117M` (default): the \"small\" model, 500MB on disk.\n",
        "* `345M`: the \"medium\" model, 1.5GB on disk.\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "outputId": "f1c866f8-bb1b-42a1-f10e-3056ee8b3669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"345M\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 270Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 114Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 263Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:10, 132Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 263Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 115Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 203Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN",
        "colab_type": "text"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab_type": "code",
        "outputId": "e1dc3f35-3110-4eec-eaed-54c881ea6b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu",
        "colab_type": "text"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p0RPmT7SOj6T",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE",
        "colab_type": "text"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. \n",
        "\n",
        "## Caution:\n",
        "For this cell to work, you must do the following steps:  \n",
        "\n",
        " 1) create the `rapper.txt` file containing the corpus of lyrics using `lyrics_dl.ipynb` on our github.  \n",
        " 2) copy those texts into the root folder of your google drive.  \n",
        " 3) update the `to_do` list with the correct file name(s).  \n",
        " 4) restart the runtime environment for each new .txt file you want to fine-tune, and update the `to_do` list accordingly.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "outputId": "dc420568-4563-457a-8917-fbe6ef9e5c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7177
        }
      },
      "source": [
        "all_rappers = [\n",
        "    'eminem.txt', 'beastie_boys.txt', 'aesop_rock.txt', 'common.txt', \n",
        "    'jayz.txt', 'mf_doom.txt', 'missy_elliott.txt', 'nas.txt', 'rza.txt'\n",
        "]\n",
        "\n",
        "to_do = ['kendrick_lamar.txt']  # no .txt file exists for this yet\n",
        "\n",
        "file_name = to_do[0]\n",
        "\n",
        "gpt2.copy_file_from_gdrive(file_name)\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='345M',\n",
        "              steps=1000,\n",
        "              learning_rate=1e-5,\n",
        "              restore_from='fresh',\n",
        "              run_name=file_name[:-4],\n",
        "              print_every=25,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )\n",
        "\n",
        "gpt2.copy_checkpoint_to_gdrive(run_name=file_name[:-4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 21:23:16.257503 139864579749760 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py:90: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0618 21:23:16.259669 139864579749760 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py:100: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0618 21:23:16.579629 139864579749760 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py:164: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0618 21:23:16.584361 139864579749760 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0618 21:23:28.652480 139864579749760 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:71: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0618 21:23:28.671540 139864579749760 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0618 21:23:28.675192 139864579749760 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:77: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "W0618 21:23:28.689783 139864579749760 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py:191: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0618 21:23:45.354236 139864579749760 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py:198: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0618 21:23:45.357015 139864579749760 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py:200: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "W0618 21:23:45.363090 139864579749760 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py:202: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0618 21:23:58.418427 139864579749760 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/345M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 135029 tokens\n",
            "Training...\n",
            "[10 | 26.10] loss=2.87 avg=2.87\n",
            "[20 | 41.20] loss=2.93 avg=2.90\n",
            "[30 | 56.44] loss=3.40 avg=3.07\n",
            "[40 | 71.80] loss=2.58 avg=2.94\n",
            "[50 | 87.28] loss=2.78 avg=2.91\n",
            "[60 | 102.90] loss=2.90 avg=2.91\n",
            "[70 | 118.60] loss=2.69 avg=2.88\n",
            "[80 | 134.43] loss=3.03 avg=2.90\n",
            "[90 | 150.34] loss=3.24 avg=2.94\n",
            "[100 | 166.35] loss=2.60 avg=2.90\n",
            "[110 | 182.43] loss=2.93 avg=2.90\n",
            "[120 | 198.52] loss=2.73 avg=2.89\n",
            "[130 | 214.59] loss=2.73 avg=2.87\n",
            "[140 | 230.62] loss=2.87 avg=2.87\n",
            "[150 | 246.67] loss=2.76 avg=2.87\n",
            "[160 | 262.69] loss=2.49 avg=2.84\n",
            "[170 | 278.75] loss=2.86 avg=2.84\n",
            "[180 | 294.82] loss=2.49 avg=2.82\n",
            "[190 | 310.87] loss=3.22 avg=2.84\n",
            "[200 | 326.96] loss=2.85 avg=2.84\n",
            "======== SAMPLE 1 ========\n",
            " like your hair is dry and it's cold\n",
            " You don't even eat it or drink it like its water\n",
            " You can't sleep on the bus anymore cause you got a headache now it's time to go\n",
            " Let me show you my new haircut I cut this shit down\n",
            " And you know what I'm up to now you can find me at homeboyz\n",
            " You can tell that you've got me on like that and I get my sh*t all on the up and up again, I'm in my house man this is homeboyz\n",
            " Yeah I know you're busy getting your shit together because me and Chris Rock got a beef then we gotta have a beef then we got to have a beef oh my God, how could he get me in jail with this bullshit so you know this is homeboyz\n",
            " All you've got to do is take one look in the mirror and say so how come you're so cool it's like you're a rockstar\n",
            " You're like a freakin' star, how are you like like you'm a rockstar? Just like you're like you're on the cover of Rock magazine, rock, rock it rock it rock it rock you rock it rock it rock it rock it rock it rock it rock it rock it rock it rock it rock it rock it rock it rock you rock it rock it rock it rock it rock it!\n",
            " Homeboyz yeah me and Chris Rock were down to the corner with our sticks in hand talking like the two of us were in the early stages of being friends and you know this was like the time of love when you thought you were on a date\n",
            " That's right let me show you how the little redhead got my heart racing like a car on fire or like you never stop I'm so mad I'd rather die like an addict\n",
            " This is my new tune 'Dope' I got it all in my mind cause I've got this new thing I'm trying to do cause I'm trying the new thing I'm trying to do cause I'm trying the new thing 'Dope'\n",
            " That's how I got a girlfriend, got her with the good looks but she was a killer bitch I'll give her some credit, she made my day man I just can't say that enough\n",
            " I didn't give a sh*t I took care of her like she was an ant farm and I said no, you don't own my land don't steal my stuff cause I'm done that I'm outta here like I heard I put out on the front porch I said hey you're a f*cking bitch 'cause you do like I told you she said, and that's my girlfriend you're a f*cking bitch 'cause you do like I told you you got me down like I'd be the one to take you out on the front porch' Cause I said, you're a f*cking bitch 'cause you put out like a f*cking drug' Cause I said that I was going out with a f*cking bitch and I said, you're a f*cking bitch you're a fucking bitch 'cause you got the mind of a f*cking drug dealer cause you don't care you're a f*cking pussy bitch'I'm outta here like I heard she said 'that's my girlfriend' cause she said yeah and that's my girlfriend 'cause when you think that you're good, then you realize that you're not so good 'cause I want to give it to a real girl 'cause when she heard I was up to doing what I like to do then she gave it to me then that's what they did, she didn't mean to cause she knew what she did but you never know what you say cause every f*cking thing will come out of your mouth as long as your mouth is open'Cause you know what you do is wrong then you come out and you start again again cause that's the way you do that, you're getting more and more nervous 'cause you feel like hell because I'm outta here all the time and when I'm out you're outta here but you're all around cause my shit's dope and my ass is all right, I can handle anything but I keep outta sight cause you have to catch me or you'll catch me too and I can put up or I can put down and that's my kind of girl, that's my type of girl'Cause I can lay down or I can keep going because I'm all in the game, if you want to get real, I've got a deal I got for you you must see but that's all that I said and no one's gonna let me go and no one's going to hear what I've been saying 'cause when I say, that's what I'm sayin' yeah no one's got a clue then you're gonna see a man that's more dangerous than me all day, every day, every moment you might never see again, cause these assholes they say that I'm not a bad\n",
            "\n",
            "[210 | 368.48] loss=2.67 avg=2.83\n",
            "[220 | 384.40] loss=2.53 avg=2.82\n",
            "[230 | 400.31] loss=2.39 avg=2.80\n",
            "[240 | 416.24] loss=2.99 avg=2.81\n",
            "[250 | 432.17] loss=3.06 avg=2.82\n",
            "[260 | 448.12] loss=2.77 avg=2.82\n",
            "[270 | 464.04] loss=2.62 avg=2.81\n",
            "[280 | 479.98] loss=2.49 avg=2.80\n",
            "[290 | 495.93] loss=3.09 avg=2.81\n",
            "[300 | 511.87] loss=2.27 avg=2.79\n",
            "[310 | 527.81] loss=2.77 avg=2.79\n",
            "[320 | 543.77] loss=2.83 avg=2.79\n",
            "[330 | 559.72] loss=3.01 avg=2.80\n",
            "[340 | 575.66] loss=2.12 avg=2.77\n",
            "[350 | 591.62] loss=2.04 avg=2.75\n",
            "[360 | 607.57] loss=2.85 avg=2.75\n",
            "[370 | 623.51] loss=2.46 avg=2.74\n",
            "[380 | 639.46] loss=2.37 avg=2.73\n",
            "[390 | 655.40] loss=1.82 avg=2.70\n",
            "[400 | 671.31] loss=2.88 avg=2.71\n",
            "======== SAMPLE 1 ========\n",
            " Watch \n",
            " I'd be on the ground if I were on this level \n",
            " If you could pick one moment in time that you were the most happy \n",
            " On one of your lucky days, just one, one in a million \n",
            " You're a rockin', you're a real nice guy, you're a real generous guy \n",
            " You're a real happy-go-lucky kind of guy, who just is \n",
            " You're an inspiration to those around you \n",
            " If you could pick one moment in time that you were the most happy \n",
            " The only thing that I could ever ask for is a miracle \n",
            "  \n",
            " [MCA] \n",
            " Well, I'm gonna do what any man would do just to get by \n",
            " I'm gonna roll with the punches, I'm gonna take what's mine \n",
            " Not a drop of sweat, no matter how much the weather's getting cold \n",
            " I get up, I get to rock, and I roll in the streets \n",
            " I roll with the rhythm, and I'm just what I am, you know \n",
            " I'm rollin' through neighborhoods and communities \n",
            " A-ha, a-ha, a-ha \n",
            " [Mike D] \n",
            " Well I'm a nigga I don't wear no shirts \n",
            " I don't smoke, I don't drink, and I'm not into that shit \n",
            " I'm all bout the beat, and 'cause I can, I ain't nothin' else \n",
            " I'm just like my name says, what you see is what you get \n",
            " You know what I'm about, and what I'm about to do \n",
            " I'm just goin', and just goin', and just going \n",
            " Got the feel, and I got the feel \n",
            "  \n",
            " [Mike D] \n",
            " Hey, it ain't nothing personal, I'm not even mad \n",
            " Hey, how about that? Is it real sweet? \n",
            " Oh my God, is it real \n",
            " I'm not mad, you know? \n",
            " M-m-m-m-m-m-m-m-m-m \n",
            " I'm not mad, you know? \n",
            " Uh-huh, yeah \n",
            " I wanna be a rapper... \n",
            " M-m-m-m-m-m-m-m-m-m \n",
            " I'm a rapper, I'm a rap \n",
            "  \n",
            " (MCA) \n",
            " M-M-M-M-M-M-M-M-M-M-M-M-M-M-I-I \n",
            " I'm gonna be a rapper, I'm a man, and I'm not makin' shit \n",
            " And I'm not gonna drink, I'm not gonna smoke, and I'm not about to let you down \n",
            " I'll be rapping, rhymin' and rapping, and no two days are the same \n",
            " Cause I'm a star, a true star \n",
            " I got the skills to be a hero \n",
            " A true hero so I can stand by my man \n",
            "  \n",
            " (Prod. by Mike D) \n",
            " Well, what do you get when you cross them and mix them up \n",
            " Your man is cool, he can put you off \n",
            " And he's still got it on, no matter what you do, he's rockin' \n",
            " Got the looks you've come to know \n",
            " And your man was not made for this world \n",
            " You say, \"Oh, cool, that's a good sound, I'll use that \n",
            " But I should have listened to the man who's spoken out \n",
            " Before I ever set foot into that place \n",
            "  \n",
            " [MCA] \n",
            " Well, I'ma mix it up with the funky, and we might rhyme together \n",
            " I'm gonna mix it up with the bass man, and I'ma rhyme with the bass \n",
            " I'm gonna mix it up with the trumpet man, and \n",
            " I'ma mix it up with the drummer, and \n",
            " All of you are going to have a party \n",
            " And I'm going to sing the national anthem \n",
            " I'm gonna get up on that dais, and sing the national anthem \n",
            " Because I'm gonna rock the streets of New York \n",
            "  \n",
            " [MCA] \n",
            " And if you wanna beat my wife, you better turn around today \n",
            " Cause I'm gonna be a rockin' and a rollin' and a rollin' \n",
            " A-ha! [Outro] \n",
            " I'm on my way, I'm in the city, what do you think \n",
            " I'm from the city, and I'm a rockin', a rollin', and a rock \n",
            " All of you are thinking about me, but I'm the one \n",
            " I'mma rhyme and rapping like MCA\n",
            "\n",
            "[410 | 709.48] loss=2.57 avg=2.70\n",
            "[420 | 725.41] loss=2.21 avg=2.69\n",
            "[430 | 741.31] loss=2.75 avg=2.69\n",
            "[440 | 757.20] loss=2.56 avg=2.69\n",
            "[450 | 773.11] loss=2.18 avg=2.67\n",
            "[460 | 789.03] loss=2.02 avg=2.66\n",
            "[470 | 804.94] loss=2.23 avg=2.64\n",
            "[480 | 820.86] loss=2.16 avg=2.63\n",
            "[490 | 836.78] loss=1.84 avg=2.61\n",
            "[500 | 852.72] loss=2.71 avg=2.61\n",
            "Saving checkpoint/beastie_boys/model-500\n",
            "[510 | 879.76] loss=2.64 avg=2.61\n",
            "[520 | 895.93] loss=2.19 avg=2.60\n",
            "[530 | 912.12] loss=2.24 avg=2.60\n",
            "[540 | 928.08] loss=1.89 avg=2.58\n",
            "[550 | 943.92] loss=2.57 avg=2.58\n",
            "[560 | 959.79] loss=2.52 avg=2.58\n",
            "[570 | 975.74] loss=2.41 avg=2.57\n",
            "[580 | 991.72] loss=1.61 avg=2.55\n",
            "[590 | 1007.70] loss=2.39 avg=2.55\n",
            "[600 | 1023.62] loss=2.21 avg=2.54\n",
            "======== SAMPLE 1 ========\n",
            " Hey \n",
            " But I can't hide this from you - baby, we're gonna talk \n",
            " About making the world a better place, and myself \n",
            " Just want to get this a little out there, ya'll \n",
            " Ain't the beat, you don't pay attention \n",
            " I do mine, you do ours, and that's right \n",
            " So what's the big deal?\" \n",
            "  \n",
            " With my heart full of joy in my soul and knowing that I'm doing well \n",
            " I'm riding on a wave of love in the air from all around the world \n",
            " So let me get this out there, my man \n",
            " With all my heart, for all the young love in the world \n",
            " For the love of all that's good that my heart holds \n",
            " \"Lets get down to it, you know we gotta get down to it \n",
            " 'Round here we go again, let's do it again \n",
            " 'Twas the year of the rabbit, let's bring it back again \n",
            " Let's get down to it,\" it's like that \n",
            " I wanna know, what's in it, let me know \n",
            " Listen up motherfuckers, that's that \n",
            "  \n",
            "  \n",
            " With my heart full of joy in my soul and knowing that I'm doing well \n",
            " I'm riding on a wave of love in the air from all around the world \n",
            " So let me get this out there, my man \n",
            " With all my heart, for all the young love in the world \n",
            " For the love of all that's good that my heart holds \n",
            " \"What's in it baby, what's in it, what's in it?\" \n",
            "  \n",
            " [Verse 2X] \n",
            " I say, baby, it's my day, baby \n",
            " It's the day of the Beastie \n",
            " You can say what you want about this or that \n",
            " My life isn't what it used to be \n",
            " You'll be sorry, your head will be fucked \n",
            " You know we're getting down \n",
            " The beats are getting rough and these are the grooves \n",
            " The beats are getting tough and these are the spots \n",
            " Get on the mic and do the Beastie shake \n",
            " We're down with the Beastie shake, baby \n",
            " 'Cause we bring it back \n",
            " Get it together, do the Beastie shake \n",
            "  \n",
            " A little something new for your pleasure \n",
            " What's up man, we're getting down \n",
            " 'Cos we bring it back! \n",
            " Oh baby, baby, baby \n",
            "  \n",
            " Baby, baby, baby \n",
            " Baby, baby \n",
            "  \n",
            " Beastie shake, come on \n",
            " 'Cause we bring it back! \n",
            " We're down with the Beastie shake \n",
            "  \n",
            " Hey yo, we're coming out \n",
            " The Beastie shake \n",
            " 'Cos we get it loose \n",
            " We're bringing it back! \n",
            " (Beastie shake) \n",
            " (Beastie shake.)You're not gonna get away from me, no \n",
            " You'd never get free from me, you know \n",
            " You're playing along, just to see it end \n",
            " It's a trap, it's a game to me, you play and you cry \n",
            " It's like a game to trap players, like a trap to a trap \n",
            " We're all trapped, all trapped, we're playing the same \n",
            " You play a trap to a trap and now you've got to play one with the shit \n",
            " We trap players and we play it and we curse it \n",
            " You play a trap to a trap and now you've got to play one with the crap \n",
            " We're all trapped, all trapped, and it's a trap \n",
            " We're all trapped, all trapped, just the shit \n",
            " We're making love to this, it's a trap \n",
            " All of its a trap \n",
            " You go with that thing, you're a trap \n",
            " You're all trapped, all trapped \n",
            " All trapped \n",
            "  \n",
            " All traps, this one is a trap \n",
            " All traps, this one is a trap \n",
            " All traps, this one is a trap \n",
            "  \n",
            " \"Hang 'em all,\" the whole crew, that's what I said \n",
            " You know I'm a real deal, man, a big shit \n",
            " I'll take care of your shit with my own two hands \n",
            " I don't know what you're talkin' about but I'm talkin' \n",
            " And I ain't got no tricks on me, I'm talkin' \n",
            " I'll take care of your shit with my own two hands \n",
            " I don't know what you're talkin' about but I'm talkin' \n",
            " I'll take care of you with my own two hands \n",
            " I don't know what you're talkin' about but I don't know \n",
            " The m\n",
            "\n",
            "[610 | 1061.82] loss=2.53 avg=2.54\n",
            "[620 | 1077.73] loss=1.92 avg=2.53\n",
            "[630 | 1093.63] loss=2.18 avg=2.52\n",
            "[640 | 1109.54] loss=2.49 avg=2.52\n",
            "[650 | 1125.46] loss=1.76 avg=2.50\n",
            "[660 | 1141.38] loss=1.67 avg=2.49\n",
            "[670 | 1157.32] loss=1.72 avg=2.47\n",
            "[680 | 1173.26] loss=1.85 avg=2.46\n",
            "[690 | 1189.19] loss=1.50 avg=2.44\n",
            "[700 | 1205.15] loss=2.46 avg=2.44\n",
            "[710 | 1221.09] loss=0.87 avg=2.41\n",
            "[720 | 1237.05] loss=2.26 avg=2.41\n",
            "[730 | 1253.00] loss=2.47 avg=2.41\n",
            "[740 | 1268.96] loss=2.08 avg=2.40\n",
            "[750 | 1284.94] loss=1.72 avg=2.39\n",
            "[760 | 1300.93] loss=1.33 avg=2.37\n",
            "[770 | 1316.87] loss=1.78 avg=2.36\n",
            "[780 | 1332.79] loss=1.08 avg=2.33\n",
            "[790 | 1348.70] loss=1.65 avg=2.32\n",
            "[800 | 1364.64] loss=1.95 avg=2.31\n",
            "======== SAMPLE 1 ========\n",
            " We all know that, but that's not true. The truth is I like to eat it!\n",
            "\n",
            " I like to eat it!\n",
            "\n",
            " I like to eat it!\n",
            "\n",
            " I like to eat it!\n",
            "\n",
            " I like to eat it \n",
            "\n",
            " The way I like to eat it it's all in my mind \n",
            "  <|endoftext|>The new season is upon us and we're feeling great. The boys have been out and out working the graveyard shift the last few years because our weekly schedule is one heck of a bitch to manage! So we thought it was only fair to give you all one big treat and give you all a special one off episode and a special bonus episode every three months and a special one time release for every live show that we air on the L! This is gonna be so awesome and when you see this show it's no lie we're just getting started....\n",
            "\n",
            "LIMITED EDITION MIX TAPE OF \"SENATORS OF THE DEMIS\"\n",
            "\n",
            "(with Matt Czuchry) \n",
            "\n",
            "(with Matt Czuchry) \n",
            "\n",
            "(with Matt Czuchry) \n",
            "\n",
            "LIMITED EDITION TAPE OF \"SENATORS OF THE DEMIS\"\n",
            "\n",
            "(with Matt Czuchry)\n",
            "\n",
            "(with Matt Czuchry) \n",
            "\n",
            "(With Matt Czuchry) \n",
            "\n",
            "LIMITED EDITION TAPE OF \"SENATORS OF THE DEMIS\"\n",
            "\n",
            "LIMITED EDITION TAPE OF \"SENATORS OF THE DEMIS\"\n",
            "\n",
            "(With Matt Czuchry) \n",
            "\n",
            "(With Matt Czuchry) \n",
            "\n",
            "LIMITED EDITION TAPE OF \"SENATORS OF THE DEMIS\"\n",
            "\n",
            "LIMITED EDITION TAPE OF \"SENATORS OF THE DEMIS\"\n",
            "\n",
            "(With Matt Czuchry)\n",
            "\n",
            "LIMITED EDITION TAPE OF \"SENATORS OF THE DEMIS\" \n",
            "\n",
            "LIMITED EDITION TAPE OF \"SENATORS OF THE DEMIS\"\n",
            "\n",
            "I could do a star trek with you \n",
            " A star trek with you \n",
            "  \n",
            " I could do a star trek with you \n",
            " A star trek with you \n",
            "  \n",
            " I could do a star trek with youI could do a star trek with youAnd then we got down like this for an hour and thirty four seconds and it was a blast and then we changed up the lyrics because I dunno, we're old school and that's a fact and we go way back and if you listen to this song now and that's the case I don't know if you wanna hear this or you should but I swear if you say that song all day every day it'd be like the peace sign would vibrate and you'd turn it on, \n",
            "  \n",
            " and if you wanna talk about that in the morning and the way the word is used \n",
            " It ain't no hype, I ain't no connoisseur, \n",
            " It's not no mind reader, I don't read books that's what I read \n",
            "  \n",
            " I just can't stand it when people's stories are altered \n",
            " I just can't stand it when people mess with truth \n",
            " I just can't stand it when people lie to fill the head space \n",
            "  \n",
            " I hate all the people out there just lying \n",
            " I hate talking about their problems, \n",
            " I don't know what's going on in their world \n",
            "  \n",
            " I hate all the people out there being so dishonest \n",
            " I hate talking about what's going on in peoples' world \n",
            " So here's a thought for ya, \n",
            " If the world could just open up a little wider \n",
            " Then we could all be the things we really wanted to beFor seven glorious seconds in this world we have \n",
            " And now we're all but gone \n",
            " Here's one more chance, \n",
            " The very last chance, \n",
            " To see a star through the glass back door \n",
            "  \n",
            " I am aware that I am nothing (nothing), (nothing), nothing (nothing) \n",
            " I am aware that I am nothing (nothing), (nothing), nothing (nothing) \n",
            " I am aware that I am nothing (nothing), (nothing), nothing (nothing) \n",
            " I wish to life and death (life and death) all day \n",
            " I wish to live and die in the moment \n",
            " I go by the name Aaliyah \n",
            " I don't like to talk anymore cause I don't know what to say \n",
            "  \n",
            " I feel like I'm living out a dream, \n",
            " It feels so natural, \n",
            " I don't know why \n",
            "  \n",
            " And I think you have me in a trance \n",
            " Cause I just don't feel like talking about \n",
            " I feel like the truth is coming out now \n",
            "  \n",
            " I wish\n",
            "\n",
            "[810 | 1402.75] loss=1.55 avg=2.30\n",
            "[820 | 1418.64] loss=2.09 avg=2.30\n",
            "[830 | 1434.56] loss=1.90 avg=2.29\n",
            "[840 | 1450.46] loss=2.41 avg=2.29\n",
            "[850 | 1466.40] loss=1.76 avg=2.28\n",
            "[860 | 1482.34] loss=1.61 avg=2.27\n",
            "[870 | 1498.32] loss=2.03 avg=2.27\n",
            "[880 | 1514.29] loss=1.96 avg=2.26\n",
            "[890 | 1530.23] loss=0.71 avg=2.24\n",
            "[900 | 1546.23] loss=1.22 avg=2.22\n",
            "[910 | 1562.22] loss=2.03 avg=2.22\n",
            "[920 | 1578.17] loss=1.91 avg=2.21\n",
            "[930 | 1594.12] loss=1.13 avg=2.19\n",
            "[940 | 1610.12] loss=1.98 avg=2.19\n",
            "[950 | 1626.08] loss=2.04 avg=2.19\n",
            "[960 | 1642.02] loss=1.20 avg=2.17\n",
            "[970 | 1657.98] loss=1.37 avg=2.16\n",
            "[980 | 1673.95] loss=1.39 avg=2.15\n",
            "[990 | 1689.90] loss=1.63 avg=2.14\n",
            "[1000 | 1705.82] loss=2.61 avg=2.14\n",
            "Saving checkpoint/beastie_boys/model-1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0618 21:52:43.313658 139864579749760 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K",
        "colab_type": "text"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name=file_name[:-4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd",
        "colab_type": "text"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L",
        "colab_type": "text"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "artists = [x[:-4] for x in all_rappers]\n",
        "\n",
        "for artist in artists:\n",
        "  gpt2.copy_checkpoint_from_gdrive(run_name=artist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV",
        "colab_type": "text"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name=artist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model. \n",
        "\n",
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text.\n",
        "\n",
        "---\n",
        "\n",
        "We will combine some logic into one cell, so we only need to `shift + enter` once, regardless of whether we restarted the runtime enviroment or not.  \n",
        "\n",
        "### The available rappers are: \n",
        "\n",
        "```'eminem',\n",
        " 'beastie_boys',\n",
        " 'aesop_rock',\n",
        " 'common',\n",
        " 'jayz',\n",
        " 'mf_doom',\n",
        " 'missy_elliott',\n",
        " 'nas',\n",
        " 'rza'```\n",
        " \n",
        " ### NOTE: You must restart if you change artists, but not if you want another verse from the same artist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "c1104f3d-fe8c-454e-f67d-dcf8ba512f5e"
      },
      "source": [
        "first_line = \"Babys are cute, they bring me joy\"\n",
        "artist = 'eminem'\n",
        "\n",
        "if artist == 'eminem':\n",
        "  artist_run = 'run1'\n",
        "else:\n",
        "  artist_run = artist\n",
        "\n",
        "try:\n",
        "  output = gpt2.generate(\n",
        "       sess,\n",
        "       run_name=artist_run,\n",
        "       length=500,\n",
        "       temperature=0.80,\n",
        "       prefix=first_line,\n",
        "       nsamples=1,\n",
        "       batch_size=1\n",
        "       )\n",
        "\n",
        "  print(output)\n",
        "  \n",
        "except:\n",
        "  import gpt_2_simple as gpt2\n",
        "  #gpt2.copy_checkpoint_from_gdrive(run_name=artist)\n",
        "  sess = gpt2.start_tf_sess()\n",
        "\n",
        "  gpt2.load_gpt2(sess, run_name=artist_run)\n",
        "\n",
        "  output = gpt2.generate(\n",
        "       sess,\n",
        "       run_name=artist_run,\n",
        "       length=500,\n",
        "       temperature=0.80,\n",
        "       prefix=first_line,\n",
        "       nsamples=1,\n",
        "       batch_size=1\n",
        "       )\n",
        "\n",
        "  print(output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Babys are cute, they bring me joy \n",
            " When they see me with a male companion \n",
            " They run, they jump, they act all wild \n",
            " But they know they're in the wrong neighborhood \n",
            " They see me throw punches, I don't mean to push the point \n",
            " But that Mr. K-Fed is a man, the real beef is with the motherfuckers \n",
            " That's why you see 'em clapping hands, and they're loud \n",
            " But you hear 'em saying, \"Go, David, go!\" \n",
            " So go, David, go! \n",
            " But don't go in there just yet \n",
            "  \n",
            " [Chorus: Royce da 5'9\"] \n",
            " On the one hand, I got meat on my plate \n",
            " But every now and then I get a craving \n",
            " To be on the other hand, you see \n",
            " I'ma make you eat my foil \n",
            " But first, I'd like to toast \n",
            "  \n",
            " [Verse 5: Royce da 5'9\"] \n",
            " I ain't known no one like you \n",
            " I'd make the world a better place \n",
            " If you only knew the truth \n",
            " I'ma make you eat my foil \n",
            " But first, I'd like to toast \n",
            "  \n",
            " [Chorus: Royce da 5'9\"] \n",
            " On the one hand, I got meat on my plate \n",
            " But every now and then I get a craving \n",
            " To be on the other hand, you see \n",
            " I'ma make you eat my foil \n",
            " But first, I'd like to toast \n",
            "  \n",
            " [Verse 6: Royce da 5'9\"] \n",
            " It's just like old times, the good ol' days \n",
            " When I used to whip up a batch of IPA \n",
            " With Christ on a clear day, boom \n",
            " And all the kids run and jump from the tops of the building \n",
            " That's why I came to stand before you \n",
            " And started to spit the verse \n",
            " You probably heard it first \n",
            " But the fact is, we ain't never seen nor is he seen \n",
            " The dude jumpin' out of a fuckin' plane, in the fuckin' same spot \n",
            " In the fuckin' same fuckin' t-shirt, same fuckin' hairstyle \n",
            " The only thing that separates the good guys and the bad guys is their clothes \n",
            " And they're\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2",
        "colab_type": "text"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp and then download it.\n",
        "\n",
        "You can rerun the cell as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )\n",
        "\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD",
        "colab_type": "text"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail or out-of-memory/OOM), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E",
        "colab_type": "text"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}